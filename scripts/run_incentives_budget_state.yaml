# Number of training episodes for the RL agent
episodes: 500

### Weights for different components of the reward/cost function
# Weight for Total Travel Time (TTT) of the network
TTT_weight: 0
# Weight for individual travel time of each agent
individual_travel_time_weight: 1
# Weight for minimising individual emissions
emissions_weight: 0
# Total emissions weight
total_emissions_weight: 0

# Exploration rate for epsilon-greedy policy
epsilon: 0.9
# Epsilon decay rate per episode (to reduce exploration over time)
decay: 0.992
# Learning rate (Î±) for Q-learning or other value update algorithms
alpha: 0.1
# Whether to use incentives or not
incentives_mode: true
# Total available budget for incentives or policies (can be used as a constraint)
total_budget:
  - 50000
  - 100000000
# Select route selection strategy
strategy: "logit"
# Store all the paths
paths_dict:
  # Path of output.rou.alt file
  output_rou_alt_path: "data/output.rou.alt.xml"
  # Path of output.rou file
  routes_file_path: "data/output.rou.xml"
  # Path for edge data frequency config
  edge_data_path: "data/edge_data.add.xml"
  # Path for SUMO log
  log_path: "data/log.xml"
  # Path to write emissions data
  emissions_path: "data/fcd.xml"
  # Path to emissions data per vehicle
  emissions_per_vehicle_path: "data/emissions_per_vehicle.txt"
  # Path to stats data after simulation
  stats_path: "data/stats.xml"
  # Path to tripinfo file
  trip_info_path: "data/tripinfo.xml"
  edges_weights_path: "weights.xml"

# Parameters needed to run SUMO
sumo_config:
  config_path: "data/config.sumocfg"
  network_path: "data/kamppi.net.xml"
  routes_path: "data/output.rou.xml"

# Edge data frequency
edge_data_frequency: 500

